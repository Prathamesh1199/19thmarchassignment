{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3823df15-8083-4f28-a3e6-df735c9431d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "1:\n",
    "    Missing values in a dataset are values that are not present for certain observations or\n",
    "variables. This can occur due to a variety of reasons such as human error, data corruption,\n",
    "or failure to capture data. Missing values can be represented in different ways such as \n",
    " \"N/A\", \"NaN\", or \"null\" depending on the software or programming language being used.\n",
    "\n",
    "It is essential to handle missing values because they can affect the accuracy and reliability \n",
    "of data analysis results. Missing data can lead to biased or incorrect conclusions, and can also\n",
    "impact the performance of machine learning algorithms.\n",
    "\n",
    "Some machine learning algorithms that are not affected by missing values include tree-based methods\n",
    "such as decision trees, random forests, and gradient boosting, as well as some clustering algorithms\n",
    "like K-Means clustering. These algorithms are designed to handle missing values and can impute or \n",
    "ignore missing values during the training process. However, its always good practice to handle missing\n",
    "values appropriately to avoid any potential issues in the analysis\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc27ec9-b6a0-4459-82e2-9d7ba9b2c274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a600af6f-37eb-4e8e-887d-93178394da96",
   "metadata": {},
   "outputs": [],
   "source": [
    "2:There are several techniques to handle missing data in a dataset. Here are some commonly used\n",
    "techniques with examples in Python:\n",
    "    \n",
    "1.Deletion: In this technique, the rows or columns with missing values are removed from the \n",
    "            dataset. This method can be useful when the amount of missing data is small and won't significantly\n",
    "            affect the analysis. There are two types of deletion techniques:\n",
    "    \n",
    "a. 'Listwise deletion: Removes any row with missing data.    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87916037-2780-45d3-b4e1-02a3762204d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B   C\n",
      "0  1.0  5.0   9\n",
      "3  4.0  8.0  12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# create a sample dataframe\n",
    "df = pd.DataFrame({'A': [1, 2, np.nan, 4], 'B': [5, np.nan, np.nan, 8], 'C': [9, 10, 11, 12]})\n",
    "\n",
    "# using listwise deletion\n",
    "df_dropna = df.dropna()\n",
    "\n",
    "print(df_dropna)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b803ce47-8b07-429a-8d04-eef26d69ed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.' Pairwise deletion: Removes any row with missing data for a particular variable or analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb6a6d26-2617-43f5-b6fb-9b800de4351f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B   C\n",
      "0  1.0  5.0   9\n",
      "3  4.0  8.0  12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# create a sample dataframe\n",
    "df = pd.DataFrame({'A': [1, 2, np.nan, 4], 'B': [5, np.nan, np.nan, 8], 'C': [9, 10, 11, 12]})\n",
    "\n",
    "# using pairwise deletion\n",
    "df_dropna = df.dropna(subset=['B'])\n",
    "\n",
    "print(df_dropna)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6654623f-b514-4d06-8aee-844c2ea66fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "2.Imputation: In this technique, the missing values are replaced with estimated values. \n",
    "             There are several methods to impute missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2f2141-51e9-4b85-84fa-0c840787032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a. 'Mean imputation: Replace the missing value with the mean of that variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9db8375e-e56b-4351-84a0-fdfc70d9ee85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          A    B   C\n",
      "0  1.000000  5.0   9\n",
      "1  2.000000  6.5  10\n",
      "2  2.333333  6.5  11\n",
      "3  4.000000  8.0  12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# create a sample dataframe\n",
    "df = pd.DataFrame({'A': [1, 2, np.nan, 4], 'B': [5, np.nan, np.nan, 8], 'C': [9, 10, 11, 12]})\n",
    "\n",
    "# using mean imputation\n",
    "df_mean = df.fillna(df.mean())\n",
    "\n",
    "print(df_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f816a2a-df98-4a7e-9ee1-2e713bac7e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b. 'Median imputation: Replace the missing value with the median of that variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da1b2687-8e9a-4336-b080-4990c04987bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B   C\n",
      "0  1.0  5.0   9\n",
      "1  2.0  6.5  10\n",
      "2  2.0  6.5  11\n",
      "3  4.0  8.0  12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# create a sample dataframe\n",
    "df = pd.DataFrame({'A': [1, 2, np.nan, 4], 'B': [5, np.nan, np.nan, 8], 'C': [9, 10, 11, 12]})\n",
    "\n",
    "# using median imputation\n",
    "df_median = df.fillna(df.median())\n",
    "\n",
    "print(df_median)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f6d41a-ed35-4d74-b720-48fa5e5b1ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "3.Hot deck imputation: In this technique, the missing value is replaced with a value from a \n",
    "                        similar record in the same dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03f70077-4d30-48e5-bc5d-8e1611425d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B   C\n",
      "0  1.0  5.0   9\n",
      "1  2.0  5.0  10\n",
      "2  NaN  5.0  11\n",
      "3  4.0  8.0  12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# create a sample dataframe\n",
    "df = pd.DataFrame({'A': [1, 2, np.nan, 4], 'B': [5, np.nan, np.nan, 8], 'C': [9, 10, 11, 12]})\n",
    "\n",
    "# using hot deck imputation\n",
    "df['B'] = df['B'].fillna(method='ffill')\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9804673c-bc02-49f8-9605-dfbabe71167a",
   "metadata": {},
   "outputs": [],
   "source": [
    "4.K-nearest neighbors imputation: In this technique, the missing value is replaced with the \n",
    "                                  average of the k-nearest neighbors in the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db461468-8a68-49b7-b9ca-291a1d1fd290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B     C\n",
      "0  1.0  5.0   9.0\n",
      "1  2.0  6.5  10.0\n",
      "2  3.0  6.5  11.0\n",
      "3  4.0  8.0  12.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# create a sample dataframe\n",
    "df = pd.DataFrame({'A': [1, 2, np.nan, 4], 'B': [5, np.nan, np.nan, 8], 'C': [9, 10, 11, 12]})\n",
    "\n",
    "# using k-nearest neighbors imputation\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "df_knn = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "print(df_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b343b06c-d19f-4e63-8bb9-fd098edfdf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52b07e2-f958-4a8f-a978-76ed9e62a90c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a16d26-fb7f-4299-9a7b-2fa39e7e02ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "3:\n",
    "   Imbalanced data refers to a situation where the distribution of classes in the target variable\n",
    "is not equal. In other words, one class has significantly more or fewer samples than the other classes.\n",
    "For example, in a binary classification problem, if the positive class has only 10% of the total samples,\n",
    "while the negative class has 90%, then we have an imbalanced dataset.\n",
    "\n",
    "If imbalanced data is not handled, it can lead to biased machine learning models that have poor performance\n",
    "in predicting the minority class. This is because the model is biased towards the majority class due to its \n",
    "prevalence in the dataset. The model might classify all instances as belonging to the majority class, resulting\n",
    "in poor predictive accuracy for the minority class.\n",
    "\n",
    "Moreover, since the model is not optimized for the minority class, it might fail to detect important patterns\n",
    "or signals that are unique to the minority class. This can be especially problematic if the minority class is\n",
    "associated with a critical outcome, such as a disease diagnosis, where failing to detect true positives can \n",
    "have serious consequences.\n",
    "\n",
    "Therefore, it is essential to handle imbalanced data to ensure that the machine learning model is trained to \n",
    "capture patterns from both classes equally. There are various techniques available for handling imbalanced data,\n",
    "such as oversampling the minority class, undersampling the majority class, or generating synthetic samples using\n",
    "techniques like SMOTE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319dba00-d16c-4272-bd21-57116e010208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eb6274-6a0a-46bd-b0c9-15ab2fba66b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "4:\n",
    " 'Upsampling' and 'downsampling' are techniques used for handling imbalanced data in machine\n",
    "    learning.\n",
    "\n",
    "'Upsampling' refers to the process of increasing the number of samples in the minority class to\n",
    "balance the class distribution. This can be achieved by either duplicating existing samples\n",
    "or by generating new synthetic samples. The goal of upsampling is to provide more representation\n",
    "to the minority class so that the machine learning model can learn from it more effectively.\n",
    "\n",
    "For example, suppose we have a dataset with 1000 samples, where 900 belong to the majority class\n",
    "and 100 belong to the minority class. In this case, we can upsample the minority class by randomly\n",
    "duplicating some of its samples to increase its size, so that it becomes closer in size to the\n",
    "majority class.\n",
    "\n",
    "\n",
    "\n",
    "'Downsampling', on the other hand, refers to the process of reducing the number of samples in the\n",
    "majority class to balance the class distribution. This can be achieved by randomly removing some\n",
    "samples from the majority class. The goal of downsampling is to reduce the effect of the majority\n",
    "class on the machine learning model and to give the minority class an equal chance to be represented.\n",
    "\n",
    "For example, suppose we have a dataset with 1000 samples, where 900 belong to the majority class and\n",
    "100 belong to the minority class. In this case, we can downsample the majority class by randomly removing\n",
    "some of its samples so that it becomes closer in size to the minority class.\n",
    "\n",
    "Whether to use up-sampling or down-sampling depends on the specific problem and the class distribution in \n",
    "the dataset. If the minority class is significantly underrepresented and has very few samples, then upsampling\n",
    "can be used to increase the representation of the minority class. On the other hand, if the majority class is\n",
    "much larger than the minority class and has many more samples, then downsampling can be used to reduce the bias\n",
    "towards the majority class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0ffa56-a442-4b9e-b67f-4bbd015252b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26239766-dff8-42dd-9f5a-ff3dc015059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "5:\n",
    "    Data augmentation is a technique used to artificially increase the size of a dataset by \n",
    "creating new samples from the existing ones. The goal of data augmentation is to provide more \n",
    "variation to the dataset, which can help improve the robustness and generalization of machine learning models.\n",
    "\n",
    "'SMOTE' (Synthetic Minority Over-sampling Technique) is a popular data augmentation technique used for\n",
    "handling imbalanced datasets, where the minority class has very few samples. The SMOTE algorithm generates\n",
    "synthetic samples by interpolating between the samples of the minority class. The algorithm selects two samples\n",
    "from the minority class and creates a new sample that is a random linear combination of the two samples.\n",
    "\n",
    "For example, suppose we have a dataset with 1000 samples, where 900 belong to the majority class and 100 belong\n",
    "to the minority class. In this case, we can use SMOTE to generate new synthetic samples for the minority class by\n",
    "interpolating between its existing samples. The algorithm selects two samples from the minority class and creates\n",
    "a new sample that is a random linear combination of the two samples. This process is repeated for each sample in \n",
    "the minority class to generate a new set of synthetic samples.\n",
    "\n",
    "The new synthetic samples generated by SMOTE are similar to the original samples of the minority class, but they\n",
    "have small variations that can help improve the generalization of the machine learning model. SMOTE is a powerful\n",
    "technique for handling imbalanced datasets, as it can generate new samples that can capture the complexity of the\n",
    "minority class and improve the performance of machine learning models.\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7091db-bcde-431a-9dd8-ae2756a50888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2495829-c266-485e-84cf-fd61e0175a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "6:\n",
    "    Outliers are data points that are significantly different from other data points in a dataset.\n",
    "They can be identified as data points that lie far away from the other data points or data points\n",
    "that have extreme values. Outliers can be caused by various factors, such as measurement errors, \n",
    "data entry errors, or natural variations in the data.\n",
    "\n",
    "It is essential to handle outliers in a dataset because they can have a significant impact on the results \n",
    "of statistical analyses and machine learning models. Outliers can skew the distribution of the data, affect\n",
    "the estimates of the mean and variance, and lead to incorrect conclusions about the data. In machine learning,\n",
    "outliers can cause models to overfit to the training data and perform poorly on new data.\n",
    "\n",
    "Handling outliers can involve various techniques, such as removing them from the dataset, transforming them \n",
    "using mathematical functions, or replacing them with more reasonable values. The choice of technique depend\n",
    " on the specific problem and the nature of the outliers in the dataset.\n",
    "\n",
    "Overall, handling outliers is essential for ensuring the accuracy and reliability of statistical analyses and\n",
    "machine learning models. By removing or transforming outliers, we can reduce the impact of their influence on \n",
    "the results and improve the overall performance of the analysis or model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf7bd42-db73-43cf-8b53-92a782b815f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fbdcfa-5b6d-4701-b418-c2d7a508dd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "7:\n",
    "  There are several techniques that can be used to handle missing data in customer data analysis:  \n",
    "    \n",
    "1.Deletion\n",
    "2.Imputation\n",
    "3.Forward and backward filling\n",
    "4.K-Nearest Neighbors (KNN) imputation\n",
    "    The choice of technique depends on the nature and extent of the missing data in the dataset and \n",
    "the specific requirements of the analysis. For example, if the missing data is limited, then deletion\n",
    "may not be necessary. However, if the missing data is extensive, then imputation techniques such as mean\n",
    "imputation or KNN imputation may be more appropriate. The goal is to handle the missing data in a way that\n",
    "preserves the integrity of the data and provides reliable results for the analysis.\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c27872b-8771-4743-8c65-2a0ad135c7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e597dc-80e4-4ab4-8500-b03c007178bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "8:\n",
    "  There are several strategies that can be used to determine if the missing data is missing\n",
    "at random or if there is a pattern to the missing data:  \n",
    "    \n",
    "1.Visual inspection\n",
    "2.Statistical tests\n",
    "3. Imputation techniques\n",
    "\n",
    "    The choice of strategy depends on the nature of the data and the specific research question. \n",
    "By identifying if there is a pattern to the missing data, researchers can make more informed \n",
    "decisions about how to handle the missing data and the potential impact on their analysis.   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0c746d-2f2e-465b-a0f3-b5a3f5be2afa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8f062c-1c9d-48db-b866-76f374cb3fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "9:\n",
    "  When dealing with imbalanced datasets, there are several strategies that can be used to\n",
    "evaluate the performance of a machine learning model:  \n",
    "    \n",
    "1.Confusion matrix: The confusion matrix is a useful tool for evaluating the performance of a\n",
    "model on an imbalanced dataset. It shows the number of true positives, true negatives, false positives,\n",
    "and false negatives, which can be used to calculate metrics such as precision, recall, and F1 score.\n",
    "\n",
    "2.ROC curve: The receiver operating characteristic (ROC) curve is another useful tool for evaluating\n",
    "the performance of a model on an imbalanced dataset. It plots the true positive rate against the false \n",
    "positive rate at various threshold settings and can be used to calculate the area under the curve (AUC).\n",
    "\n",
    "3.Resampling techniques: Resampling techniques such as oversampling or undersampling can be used to balance \n",
    "the dataset and improve the performance of the model on the minority class. For example, oversampling the\n",
    "minority class can be done using techniques like SMOTE.\n",
    "\n",
    "4.Cost-sensitive learning: Cost-sensitive learning involves assigning different costs or weights to different\n",
    "classes in the dataset. This can be used to penalize misclassifications of the minority class more heavily and \n",
    "improve the performance of the model on the minority class.\n",
    "    \n",
    "    The choice of strategy depends on the nature of the data and the specific research question. By evaluating \n",
    "the performance of the model on the minority class, researchers can make more informed decisions about how to \n",
    "handle the imbalanced data and the potential impact on their analysis.\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8ed642-0465-43a1-b548-9d56343521a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054e59ff-c58e-4765-b67a-ebb4a1bcc074",
   "metadata": {},
   "outputs": [],
   "source": [
    "10:\n",
    "   To balance an unbalanced dataset with a majority class, down-sampling can be used to reduce\n",
    "the number of samples in the majority class to match the minority class. This can be done by\n",
    "randomly selecting a subset of the majority class samples equal to the number of minority class samples.\n",
    "\n",
    "The following are some methods that can be employed to down-sample the majority class: \n",
    "    \n",
    "1.Random under-sampling: This involves randomly selecting a subset of the majority class samples equal to\n",
    "the number of minority class samples. This can be done using the \"sample\" method in pandas.\n",
    "\n",
    "2.Cluster centroid under-sampling: This involves clustering the majority class samples and then selecting \n",
    "the centroids of each cluster as representatives for the majority class. This can be done using the\n",
    "\"ClusterCentroids\" method in the imbalanced-learn package.\n",
    "\n",
    "3.Tomek links: Tomek links are pairs of samples in the dataset that are of different classes but are very \n",
    "close to each other. Removing the majority class samples from these pairs can help balance the dataset.\n",
    "This can be done using the \"TomekLinks\" method in the imbalanced-learn package.    \n",
    "   \n",
    "    After down-sampling, the dataset can be re-sampled using techniques like cross-validation to \n",
    "ensure that the model is trained and tested on a representative sample of the data.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6581faa-6248-48ef-84e9-2859a6998708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b009ab32-0760-4e8d-89bd-231e6a33fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "11:\n",
    "   To balance an unbalanced dataset with a minority class, up-sampling can be used to increase\n",
    "the number of samples in the minority class to match the majority class. This can be done by\n",
    "creating new synthetic samples that are similar to the existing minority class samples.\n",
    "\n",
    "The following are some methods that can be employed to up-sample the minority class:\n",
    "\n",
    "1.Random over-sampling: This involves randomly duplicating the minority class samples until \n",
    "the number of minority class samples is equal to the number of majority class samples. This can \n",
    "be done using the \"sample\" method in pandas.\n",
    "\n",
    "2.Synthetic Minority Over-sampling Technique (SMOTE): SMOTE creates new synthetic samples by\n",
    "interpolating between existing minority class samples. This helps to ensure that the synthetic\n",
    "samples are not exact duplicates of existing samples. This can be done using the \"SMOTE\" method\n",
    "in the imbalanced-learn package.\n",
    "\n",
    "3.Adaptive Synthetic (ADASYN): This method generates more synthetic samples for minority class \n",
    "samples that are harder to learn, and fewer synthetic samples for easy-to-learn minority class \n",
    "samples. This can be done using the \"ADASYN\" method in the imbalanced-learn package.\n",
    "\n",
    "  After up-sampling, the dataset can be re-sampled using techniques like cross-validation to ensure\n",
    "that the model is trained and tested on a representative sample of the data.   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2d00b7-eeda-4391-b350-59a0bd6ba161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef0a3ff-a8f1-418f-9a9c-c9ed0dcc0447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed8ac9e-07d2-4543-ae70-c7124b8fa579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b40aa7-4f9b-4f6b-b201-e1decd8ac358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
